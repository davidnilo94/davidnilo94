---
layout: posts
date: '2018-10-03 09:00 +0200'
image: /media/fdsa.png
disqus: true
published: true
title: Ética vs estadística
---
## Ética vs estadística

## disyunción más que complicada

![RightWrong]({{site.baseurl}}/media/dsQW.png)


Un agente de policía resentido con el mundo de la robótica, por haber salvado su vida frente a la de una niña en un accidente de tráfico. Por detrás, un cálculo de probabilidad de una inteligencia artificial, en el que el agente resultaba favorecido en detrimento de la pequeña.

Esto es sólo un argumento de una película (Yo Robot, protagonizada por Will Smith), que pretendía ser futurista, y, por tanto, de ciencia ficción para la época (2004).
Pero como bien dicen, a veces la realidad supera a la ciencia ficción, y el avance de los tiempos y la tecnología, ha hecho que este argumento, pueda ser ya más objeto de un documental de actualidad sobre aspectos plausibles en un futuro cercano, que de una película de ciencia ficción.

Como bien sabéis, las inteligencias artificiales, se crean y entrenan a partir de cantidades ingentes de datos, que convenientemente analizados y ponderados, dan lugar a unos resultados determinados. A partir de estos datos, se conforman decisiones autómatas, que la inteligencia calibra en función de los datos de entrada que se den en cada circunstancia. 
Así pues, vemos inteligencias artificiales que toman decisiones judiciales, te conceden un crédito o no por los rasgos de tu cara, o calculan la probabilidad de que te comportes de una manera u otra.

Todo esto suena muy bien, pero, ¿puede un sistema como estos plasmar la ética y la moral presente en las conductas humanas?
Sin duda, estas éticas y morales presentes en la raza humana, han sido formadas por una confluencia de factores (educativos, circunstanciales, sociales, culturales…), y juegan un papel decisivo en la toma de cualquier decisión.

![eticanubepalabras]({{site.baseurl}}/media/fdsa.png)

Pongamos un ejemplo: un Tesla con conducción autómata se debate entre dos opciones, la primera, matar a dos personas, una madre y un niño, la segunda, caer por un puente, y matar a su propietario.

¿Puede un sistema probabilístico tener en cuenta aspectos como que el niño tiene toda la vida por delante, o la ruina de las familias de las víctimas, o la pérdida económica a la compañía en el caso de acabar con la vida de su cliente?, ¿o son estas cuestiones meramente aspectos a valorar por una mente humana, dotada de ética, moral y raciocinio?

Aunque el ejemplo puede parecer enrevesado, la cantidad de variables a introducir en la relación y ponderación puede ser muy extensa, lo que hace que la complejidad de la decisión aumente exponencialmente a medida que se van añadiendo.

Por otra parte, la inteligencia aprende de vivencias de humanos, que nutren su aprendizaje. Por este motivo, un coche autónomo debería conducir mejor que un humano, ya que tiene millones de kms de aprendizaje a sus espaldas. Aunque este punto, no resuelve la inclusión de la ética y la moral en la decisión, ya que estas, varían de forma significativa de unos humanos a otros.

Muchos dirán, ¿acaso el humano tiene en cuenta todos esos factores y variables en tan sólo un segundo de reacción?, probablemente no, aunque la naturaleza humana nunca deje de sorprendernos.

